{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "new_directory = '/home/fruitspec-lab/FruitSpec/Code/roi/fsCounter'\n",
    "os.chdir(new_directory)\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1504a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MHS.F_model_training import *\n",
    "from vision.misc.help_func import go_up_n_levels\n",
    "from vision.pipelines.fe_pipeline import *\n",
    "from vision.feature_extractor.vegetation_indexes import num_deno_nan_divide, num_deno_nan_divide_np, ndvi_cuda\n",
    "\n",
    "# os.chdir(r'/home/fruitspec-lab/FruitSpec/Code/roi/fsCounter/MHS')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from vision.tools.image_stitching import plot_2_imgs\n",
    "from vision.tools.camera import is_saturated\n",
    "from vision.feature_extractor.stat_tools import get_mode\n",
    "from vision.depth.slicer.slicer import find_tree_height_limits\n",
    "from vision.misc.help_func import go_up_n_levels, validate_output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frame, xyz_frame, resize_facotr, show_imgs, vndvi_filter, vari_filter, channels_thresh):\n",
    "    org_frame = frame\n",
    "    if resize_facotr > 1:\n",
    "        new_shape = (frame.shape[1] // resize_facotr, frame.shape[0] // resize_facotr)\n",
    "        frame = cv2.resize(frame, new_shape)\n",
    "        xyz_frame = cv2.resize(xyz_frame, new_shape)\n",
    "    else:\n",
    "        frame, xyz_frame = np.copy(frame), np.copy(xyz_frame)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flatten_frame = gray_frame.flatten()\n",
    "    gray_mode = get_mode(flatten_frame)\n",
    "    if show_imgs:\n",
    "        plt.hist(flatten_frame, density = True, bins = 50)\n",
    "        plt.title(gray_mode)\n",
    "        plt.show()\n",
    "    if gray_mode < 25: # Dark image\n",
    "        vndvi_filter = vndvi_filter - 0.01\n",
    "        if np.sum(vari_filter) > 0:\n",
    "            vari_filter = (0.5, 100)\n",
    "        channels_thresh[2] = (0, 255)\n",
    "        channels_thresh[1] = (0, 255)\n",
    "    return org_frame, frame, xyz_frame, vndvi_filter, vari_filter, channels_thresh\n",
    "\n",
    "def apply_depth_filter(frame, xyz_frame, depth_filter, show_imgs):\n",
    "    if np.sum(depth_filter) > 0:\n",
    "        if show_imgs:\n",
    "            frame_pre = frame.copy()\n",
    "        depth_chanel = xyz_frame[:,:,2]\n",
    "        frame[depth_chanel < depth_filter[0]] = 0\n",
    "        frame[depth_chanel > depth_filter[1]] = 0\n",
    "        if show_imgs:\n",
    "            plot_2_imgs(frame_pre, frame, title = \"pre depth filter,    post filter\")\n",
    "    return frame\n",
    "\n",
    "def channel_filter(frame, channels_thresh, show_imgs):\n",
    "    if show_imgs:\n",
    "        frame_pre = frame.copy()\n",
    "    mask = np.ones_like(frame[:,:,0], dtype=bool)\n",
    "    for channel, thresholds in channels_thresh.items():\n",
    "        if not np.sum(thresholds):\n",
    "            continue\n",
    "        chan = frame[:, :, channel]\n",
    "        channel_mask = cv2.inRange(chan, thresholds[0], thresholds[1])\n",
    "        mask = np.bitwise_and(mask, channel_mask)\n",
    "    frame[np.where(mask==0)] = 0\n",
    "    if show_imgs:\n",
    "        plot_2_imgs(frame_pre, frame, title=\"prefilter channel, post filter\")\n",
    "    return frame\n",
    "\n",
    "def gmr_filter(gree_minus_red_thres, frame, show_imgs):\n",
    "    if np.sum(gree_minus_red_thres) != 0:\n",
    "        diff = frame[:, :, 1] - frame[:, :, 0]\n",
    "        valids = cv2.inRange(diff, gree_minus_red_thres[0], gree_minus_red_thres[1])\n",
    "        if show_imgs:\n",
    "            frame_pre = frame.copy()\n",
    "        frame[np.where(valids==0)] = 0\n",
    "        if show_imgs:\n",
    "            plot_2_imgs(frame_pre, frame, title = \"prefilter g minus r,    post filter\")\n",
    "    return frame\n",
    "\n",
    "def gmb_filter(gree_minus_blue_thres, frame, show_imgs):\n",
    "    if np.sum(gree_minus_blue_thres) !=0:\n",
    "        diff = (frame[:, :, 1] - frame[:, :, 2])/(frame[:, :, 1]+1)\n",
    "        valids = cv2.inRange(diff, gree_minus_blue_thres[0], gree_minus_blue_thres[1])\n",
    "        if show_imgs:\n",
    "            frame_pre = frame.copy()\n",
    "        frame[np.where(valids==0)] = 0\n",
    "        if show_imgs:\n",
    "            plot_2_imgs(frame_pre, frame, title = \"prefilter g minus b,    post filter\")\n",
    "    return frame\n",
    "\n",
    "def apply_vari_filter(frame, Red, Green, Blue, vari_filter, show_imgs):\n",
    "    vari = num_deno_nan_divide_np((Green - Red), (Green + Red - Blue))\n",
    "    vari[~np.isfinite(vari)] = 0\n",
    "    vari = np.clip(vari, -5,15)\n",
    "    if show_imgs:\n",
    "        frame_pre = frame.copy()\n",
    "    frame_copy = frame.copy()\n",
    "    frame_copy[vari >= vari_filter[1]]= 0\n",
    "    frame_copy[vari <= vari_filter[0]]= 0\n",
    "    frame[-int(frame.shape[0]/4):,:] = frame_copy[-int(frame.shape[0]/4):,:]\n",
    "    if show_imgs:\n",
    "        plot_2_imgs(frame_pre, frame, title = \"prefilter vari,    post filter\")\n",
    "    return frame\n",
    "\n",
    "def apply_vndvi_filter(frame, Red, Green, Blue, vndvi_filter, show_imgs):\n",
    "    vndvi = 0.5268 * (Red**(-0.1294) * Green**(0.3389)* Blue**(-0.3118))\n",
    "    vndvi[~np.isfinite(vndvi)] = np.nanmin(vndvi)\n",
    "    if show_imgs:\n",
    "        frame_pre = frame.copy()\n",
    "    frame[vndvi <= vndvi_filter] = np.nanmin(vndvi)\n",
    "    if show_imgs:\n",
    "        plot_2_imgs(frame_pre, frame, title = \"prefilter vndvi,    post filter\")\n",
    "    return frame\n",
    "\n",
    "def show_vi_filter_res(org_frame, vari_filter, vndvi_filter):\n",
    "    Red, Green, Blue = org_frame[:,:,0], org_frame[:,:,1], org_frame[:,:,2]\n",
    "    vari = num_deno_nan_divide_np((Green - Red), (Green + Red - Blue))\n",
    "    vari[~np.isfinite(vari)] = 0\n",
    "    vari = np.clip(vari, -5,10)   \n",
    "    vndvi = 0.5268 * (Red**(-0.1294) * Green**(0.3389)* Blue**(-0.3118))\n",
    "    vndvi[~np.isfinite(vndvi)] = np.nanmin(vndvi)\n",
    "    print(np.nanquantile(vndvi, 0.025), np.nanquantile(vndvi, 0.975))\n",
    "    plt.hist(vndvi.flatten(), bins = 50)\n",
    "    plt.show()\n",
    "    plot_2_imgs(vari, np.clip(vndvi, np.nanquantile(vndvi, 0.025), np.nanquantile(vndvi, 0.975)), title = \"vari,    ndvi\")\n",
    "    plot_2_imgs(cv2.inRange(vari, vari_filter[0], vari_filter[1]), vndvi > vndvi_filter, title = \"vari filtered,    ndvi filtred\")\n",
    "    \n",
    "def debug_func(frame, Red, Green, Blue):\n",
    "#     vndvi = 0.5268 * (Red**(-0.1294) * Green**(0.3389)* Blue**(-0.3118))\n",
    "#     vari = num_deno_nan_divide_np((Green - Red), (Green + Red - Blue))\n",
    "#     vari[~np.isfinite(vari)] = np.nanmin(vari)\n",
    "#     vari = np.clip(vari, -5,10)\n",
    "#     plt.hist(vari.flatten(), bins = 50)\n",
    "#     plt.show()    \n",
    "    diff0 = frame[:, :, 1] - frame[:, :, 0]\n",
    "    diff2 = frame[:, :, 1] - frame[:, :, 2]\n",
    "    plot_2_imgs(diff0, diff2, title = \"diff_0, diff_2\")\n",
    "    diff0 = (frame[:, :, 1] - frame[:, :, 0])/(frame[:, :, 1]+1)\n",
    "    diff2 = (frame[:, :, 1] - frame[:, :, 2])/(frame[:, :, 1]+1)\n",
    "    plot_2_imgs(diff0, diff2, title = \"diff_0/c1, diff_2/c1\")\n",
    "    diff0 = (frame[:, :, 1] - frame[:, :, 0])/(frame[:, :, 1]+frame[:, :, 0]+1)\n",
    "    diff2 = (frame[:, :, 1] - frame[:, :, 2])/(frame[:, :, 1]+frame[:, :, 2]+1)\n",
    "    plot_2_imgs(diff0, diff2, title = \"diff_0/sum, diff_2/sum\")    \n",
    "#     vndvi[~np.isfinite(vndvi)] = np.nanmin(vndvi)\n",
    "#     plot_2_imgs(vari, vndvi, title = \"Vari, vNDVI\")\n",
    "#     plot_2_imgs(vari < 0, vari < 0.5, title = \"Vari, vNDVI\")\n",
    "#     plot_2_imgs(vari < 1, vari < 1.5, title = \"Vari, vNDVI\")\n",
    "#     plot_2_imgs(vari < 2, vari < 2.5, title = \"Vari, vNDVI\")\n",
    "#     plot_2_imgs(vari < 3, vari < 3.5, title = \"Vari, vNDVI\")\n",
    "#     plot_2_imgs(vari < 4, vari < 4.5, title = \"Vari, vNDVI\")\n",
    "#     plot_2_imgs(vari <= 5, vari < 5.5, title = \"Vari, vNDVI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(xyz_frame, mid_height, include_y_grad):\n",
    "    depth_channel = xyz_frame[mid_height:, :, 2]\n",
    "    depth_grad = np.gradient(depth_channel)[0]\n",
    "\n",
    "    y_grad = None\n",
    "    if include_y_grad:\n",
    "        y_channel = xyz_frame[mid_height:, :, 1]\n",
    "        y_grad = np.gradient(y_channel)[0]\n",
    "\n",
    "    return depth_grad, y_grad\n",
    "\n",
    "\n",
    "def apply_thresholding(depth_grad, y_grad, min_grad = 0.01):\n",
    "    depth_grad_mask = depth_grad > min_grad\n",
    "\n",
    "    y_grad_mask = None\n",
    "    if y_grad is not None:\n",
    "        y_grad_mask = y_grad > min_grad\n",
    "\n",
    "    return depth_grad_mask, y_grad_mask\n",
    "\n",
    "\n",
    "def combine_masks(depth_grad_mask, y_grad_mask):\n",
    "    if y_grad_mask is not None:\n",
    "        return depth_grad_mask.astype(np.uint8) | y_grad_mask.astype(np.uint8)\n",
    "    else:\n",
    "        return depth_grad_mask.astype(np.uint8)\n",
    "\n",
    "\n",
    "def dilate_image(comb_img, img_h):\n",
    "    comb_img = cv2.erode(comb_img, np.ones((img_h//200+1, img_h//200 +1)), iterations=1)\n",
    "    return cv2.dilate(comb_img, np.ones((img_h//40+1, img_h//40 +1)), iterations=1)\n",
    "\n",
    "\n",
    "def find_filtered_contours(comb_img_dilated, min_contour_area):\n",
    "    contours, _ = cv2.findContours(comb_img_dilated.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours, [contour for contour in contours if cv2.contourArea(contour) >= min_contour_area*10]\n",
    "\n",
    "\n",
    "def create_output_image(xyz_frame, contours_filtered_drawed, mid_height):\n",
    "    height, width = contours_filtered_drawed.shape\n",
    "    output_img = np.zeros_like(xyz_frame)\n",
    "\n",
    "    for x in range(width):\n",
    "        column = contours_filtered_drawed[:, x]\n",
    "        min_y = len(column) - np.argmax(column[::-1]) - 1 + mid_height\n",
    "        output_img[min_y:, x] = 1\n",
    "\n",
    "    return output_img\n",
    "\n",
    "\n",
    "def segment_floor(xyz_frame, show_imgs=True, min_contour_area=100, include_y_grad=False):\n",
    "    img_h = xyz_frame.shape[0]\n",
    "    mid_height = img_h // 2\n",
    "\n",
    "    depth_grad, y_grad = calculate_gradients(xyz_frame, mid_height, include_y_grad)\n",
    "    depth_grad_mask, y_grad_mask = apply_thresholding(depth_grad, y_grad)\n",
    "\n",
    "    if show_imgs and y_grad_mask is not None:\n",
    "        plot_2_imgs(depth_grad_mask, y_grad_mask, title=\"masked grads (depth, y)\")\n",
    "\n",
    "    comb_img = combine_masks(depth_grad_mask, y_grad_mask)\n",
    "    comb_img_dilated = dilate_image(comb_img, img_h)\n",
    "\n",
    "    if show_imgs:\n",
    "        plot_2_imgs(comb_img, comb_img_dilated, title=\"org gradient image, dilated image\")\n",
    "\n",
    "    contours, filtered_contours = find_filtered_contours(comb_img_dilated, min_contour_area)\n",
    "    contours_filtered_drawed = cv2.drawContours(comb_img_dilated.copy(), filtered_contours, -1, (255, 0, 0), 1)\n",
    "\n",
    "    if show_imgs:\n",
    "        contours_drawed = cv2.drawContours(comb_img_dilated.copy(), contours, -1, (255, 0, 0), 1)\n",
    "        plot_2_imgs(contours_drawed, contours_filtered_drawed, title=\"contours, filtered contours\")\n",
    "\n",
    "    output_img = create_output_image(xyz_frame, contours_filtered_drawed, mid_height)\n",
    "\n",
    "    if show_imgs:\n",
    "        plot_2_imgs(output_img, contours_filtered_drawed, title=\"final image, filtered contours\")\n",
    "\n",
    "    return output_img\n",
    "\n",
    "def remove_floor(frame, xyz_frame, show_imgs=True):\n",
    "    if show_imgs:\n",
    "        frame_pre = frame.copy()\n",
    "    frame[segment_floor(xyz_frame, show_imgs)==1] = 0\n",
    "    if show_imgs:\n",
    "        plot_2_imgs(frame_pre, frame, title = \"prefilter floor,    post floor filter\")\n",
    "    return frame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727846e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh_channels(frame, xyz_frame, channels_thresh={0: (0, 175), 1: (10, 255), 2: (0, 200)},\n",
    "                    gree_minus_red_thres=(0, 0), gree_minus_blue_thres=(0, 0), vari_filter = (0, 0), vndvi_filter = 0.35,\n",
    "                    depth_filter = (0.75, 5),show_imgs=False, resize_facotr = 4, full_tree_thresh = 0.33):\n",
    "    \"\"\"\n",
    "    Thresholds the input frame based on the given channel thresholds and green minus red thresholds.\n",
    "\n",
    "    Args:\n",
    "        frame (ndarray): The input frame to threshold.\n",
    "        channels_thresh (dict): A dictionary containing the channel indices as keys and a tuple of thresholds as values.\n",
    "        gree_minus_red_thres (tuple): A tuple containing the green minus red thresholds.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The thresholded frame.\n",
    "\n",
    "    \"\"\"\n",
    "    org_frame, frame, xyz_frame, vndvi_filter, vari_filter, channels_thresh = preprocess(frame, xyz_frame, \n",
    "                                                                              resize_facotr, show_imgs,\n",
    "                                                                              vndvi_filter, vari_filter, \n",
    "                                                                              channels_thresh)\n",
    "    frame = remove_floor(frame, xyz_frame) #, show_imgs)\n",
    "    frame = apply_depth_filter(frame, xyz_frame, depth_filter, show_imgs)\n",
    "    if np.sum(vari_filter) + vndvi_filter > 0:\n",
    "        Red, Green, Blue = frame[:,:,0], frame[:,:,1], frame[:,:,2]\n",
    "#     if show_imgs:\n",
    "#     debug_func(frame, Red, Green, Blue)\n",
    "    \n",
    "    frame = channel_filter(frame, channels_thresh, show_imgs)\n",
    "    frame = gmr_filter(gree_minus_red_thres, frame, show_imgs)\n",
    "    frame = gmb_filter(gree_minus_blue_thres, frame, show_imgs)\n",
    "    if np.sum(vari_filter) > 0:\n",
    "        frame = apply_vari_filter(frame, Red, Green, Blue, vari_filter, show_imgs)\n",
    "    if vndvi_filter > 0:\n",
    "        frame = apply_vndvi_filter(frame, Red, Green, Blue, vndvi_filter, show_imgs)\n",
    "    if show_imgs:\n",
    "        show_vi_filter_res(org_frame, vari_filter, vndvi_filter)\n",
    "    threshed_img = cv2.threshold(frame[:, :, 1], 0, 255, cv2.THRESH_BINARY)[1] > 0\n",
    "    full_tree = np.mean(threshed_img[:threshed_img.shape[0]//15,:]) < full_tree_thresh\n",
    "    return threshed_img, full_tree\n",
    "\n",
    "def get_percent_h_seen(zed_threshed_cut, y1, y2):\n",
    "    return round(np.mean(np.nansum(zed_threshed_cut[y1:y2, :], axis = 0) / np.nansum(zed_threshed_cut, axis = 0)),2 )\n",
    "\n",
    "def get_percent_seen(zed_frame, xyz_frame, coors, return_threshed=False, show_imgs=False, resize_facotr=4):\n",
    "    x1, y1, x2, y2 = [cor//resize_facotr for cor in coors]\n",
    "    zed_threshed, full_tree = thresh_channels(zed_frame, xyz_frame,\n",
    "                                                  show_imgs=show_imgs, resize_facotr=resize_facotr)\n",
    "    zed_threshed_cut = zed_threshed[:, x1:x2]\n",
    "    percent_seen = round(np.nansum(zed_threshed_cut[y1:y2, :])/np.nansum(zed_threshed_cut),2)\n",
    "    percent_h_seen = get_percent_h_seen(zed_threshed_cut, y1, y2)\n",
    "    percent_seen_top = round(np.nansum(zed_threshed_cut[y1:y2, :])/np.nansum(zed_threshed_cut[:y2,:]),2)\n",
    "    no_tree_indicator = np.mean(zed_threshed) < 0.2\n",
    "    if return_threshed:\n",
    "        return percent_seen, percent_h_seen, percent_seen_top, no_tree_indicator, full_tree, zed_threshed_cut\n",
    "    return percent_seen, percent_h_seen, percent_seen_top, no_tree_indicator, full_tree\n",
    "\n",
    "def debug_percent_seen_batch(batch_fsi, batch_rgb_zed, batch_zed, frame_ids, b_align, debug_folder=\"\"):\n",
    "    for jai, zed, zed_xyz, f_id, cors in zip(batch_fsi, batch_rgb_zed, batch_zed, frame_ids, b_align):\n",
    "        cors = [int(cor) for cor in cors[:4]]\n",
    "        x1, y1, x2, y2 = cors\n",
    "        zed_copy = zed.copy()\n",
    "        color = (0, 0, 255)\n",
    "        thickness = 2\n",
    "        percent_seen, percent_h_seen, percent_seen_top, no_tree_indicator, full_tree, zed_threshed = get_percent_seen(zed_copy,\n",
    "                                                                                                          zed_xyz,\n",
    "                                                                                           cors[:4], True, False)\n",
    "        cv2.rectangle(zed_copy, (x1, y1), (x2, y2), color, thickness)\n",
    "        plot_name = os.path.join(debug_folder, f\"jai_zed_{f_id}.jpg\")\n",
    "        plot_name_2 = os.path.join(debug_folder, f\"threshed_zed_{f_id}.jpg\")\n",
    "        plot_2_imgs(jai, zed_copy, title=f_id, save_to=plot_name, save_only=False, cv2_save=False, quick_save=False)\n",
    "        plot_2_imgs(zed_threshed, zed_copy, title=f\"\"\"frame: {f_id}, percent: {percent_seen}, percent_top: {percent_seen_top}, percent_h_seen: {percent_h_seen}\n",
    "        full_tree: {full_tree}, no_tree_indicator: {no_tree_indicator}\"\"\",\n",
    "                    save_to=plot_name_2, save_only=False, cv2_save=False, quick_save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcca91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_row_ps(row_scan_path, min_slice_len, direction, tree_id, frames, shift, debug_folder=\"\"):\n",
    "    adts_loader = None\n",
    "    validate_jai_zed_json(row_scan_path)\n",
    "    customer_name = os.path.basename(go_up_n_levels(row_scan_path, 4))\n",
    "    block_name = os.path.basename(go_up_n_levels(row_scan_path, 3))\n",
    "    row_name = \"R\" + os.path.basename(go_up_n_levels(row_scan_path, 1)).split(\"_\")[-1]\n",
    "    if debug_folder != \"\":\n",
    "        debug_folder = os.path.join(debug_folder, f\"{block_name}_{row_name}\")\n",
    "    validate_output_path(debug_folder)\n",
    "    validate_slice_data(row_scan_path, min_slice_len=min_slice_len, direction=direction)\n",
    "    metadata, _ = get_metadata(row_scan_path)\n",
    "    fe, adts_loader, batch_size = init_fe_obj(row_scan_path, tree_id, adts_loader, False, direction)\n",
    "    n_batchs = len(frames) // batch_size\n",
    "    for i in tqdm(range(n_batchs)):\n",
    "        frame_ids = frames[i * batch_size: (i + 1) * batch_size]\n",
    "        batch_res = adts_loader.load_batch(frame_ids, shift)\n",
    "        batch_fsi, batch_zed, batch_jai_rgb, batch_rgb_zed, batch_tracker, batch_slicer, frame_ids, b_align, b_jai_translation, bps = batch_res\n",
    "        debug_percent_seen_batch(batch_fsi, batch_rgb_zed, batch_zed, frame_ids, b_align, debug_folder)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cafd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_slice_len=5\n",
    "direction=\"left\"\n",
    "frames = [str(num) for num in range(100,110)]\n",
    "tree_id = 0\n",
    "shift = 0\n",
    "os.chdir(new_directory)\n",
    "debug_folder = \"/media/fruitspec-lab/easystore/ps_debug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(new_directory)\n",
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/DEWAGD/DWDBLE33/190123/row_23/2\"\n",
    "frames = [str(num) for num in range(955,963)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, direction, tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd342c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/BEERAMU0/220823/row_107/1\"\n",
    "frames = [str(num) for num in range(56,69)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, direction, tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db3514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(new_directory)\n",
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/BEERAMU0/220823/row_107/1\"\n",
    "frames = [str(num) for num in range(100,109)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, direction, tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d7cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/ORSCHIST/230813/row_6/1\"\n",
    "frames = [str(num) for num in range(403,415)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, direction, tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd76625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/ORSCHIST/230813/row_5/1\"\n",
    "frames = [str(num) for num in range(298,310)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, direction, tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb9a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/RAUSTENB/060723/row_2/1\"\n",
    "frames = [str(num) for num in range(223,227)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79317e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/RAUSTENB/060723/row_3/1\"\n",
    "frames = [str(num) for num in range(562,566)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5645e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/MEIRAVHA/230723/row_101/1\"\n",
    "frames = [str(num) for num in range(193,197)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07e33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path =\"/media/fruitspec-lab/cam175/customers_new/PROPAL/M7XXXXXX/250323/row_23/1\"\n",
    "frames = [str(num) for num in range(1000,1009)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b5a9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/PROPAL/FUKUMOTO/260323/row_22/1\"\n",
    "frames = [str(num) for num in range(2000, 2009)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c68382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/PROPAL/2018XXXX/230323/row_62/1\"\n",
    "frames = [str(num) for num in range(1500, 1509)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/MICHAL22/240723/row_101/1\"\n",
    "frames = [str(num) for num in range(60,68)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f9fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/MICHAL22/240723/row_102/2\"\n",
    "frames = [str(num) for num in range(200,209)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e501d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/BLOCK700/170723/row_1/1\"\n",
    "frames = [str(num) for num in range(200,209)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/BLOCK700/170723/row_4/1\"\n",
    "frames = [str(num) for num in range(416,428)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233af953",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/BLAYNEY0/170723/row_10/1\"\n",
    "frames = [str(num) for num in range(336,344)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/BLAYNEY0/170723/row_12/1\"\n",
    "frames = [str(num) for num in range(380,388)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/BLOCKAT0/140823/row_4/1\"\n",
    "frames = [str(num) for num in range(745,757)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bbe34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/BLOCKAT0/140823/row_7/1\"\n",
    "frames = [str(num) for num in range(3296,3312)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c647f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/BLOCKDX0/row_9/1\"\n",
    "frames = [str(num) for num in range(1360,1368)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/BLOCKDX0/row_10/1\"\n",
    "frames = [str(num) for num in range(370,378)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/FREDIANI/170723/row_14/1\"\n",
    "frames = [str(num) for num in range(200,208)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfa856",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/FREDIANI/170723/row_15/1\"\n",
    "frames = [str(num) for num in range(397,409)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/G60CLEM0/140823/row_5/1\"\n",
    "frames = [str(num) for num in range(3199,3215)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/G60CLEM0/140823/row_11/1\"\n",
    "frames = [str(num) for num in range(663,671)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05605fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/MAZMANI2/170723/row_20/1\"\n",
    "frames = [str(num) for num in range(506, 510)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/MAZMANI2/170723/row_21/1\"\n",
    "frames = [str(num) for num in range(362,366)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/MAZMANIA/170723/row_17/1\"\n",
    "frames = [str(num) for num in range(316,324)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48838ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/MAZMANIA/170723/row_18/1\"\n",
    "frames = [str(num) for num in range(268,276)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/OLIVER55/170723/row_6/1\"\n",
    "frames = [str(num) for num in range(66,82)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/FOWLER/OLIVER55/170723/row_6/1\"\n",
    "frames = [str(num) for num in range(603,615)]\n",
    "run_on_row_ps(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift, debug_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FsCounter",
   "language": "python",
   "name": "fscounter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
