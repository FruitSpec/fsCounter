{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "new_directory = '/home/fruitspec-lab/FruitSpec/Code/roi/fsCounter'\n",
    "os.chdir(new_directory)\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1504a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MHS.F_model_training import *\n",
    "from vision.misc.help_func import go_up_n_levels\n",
    "from vision.pipelines.fe_pipeline import *\n",
    "from vision.feature_extractor.vegetation_indexes import num_deno_nan_divide, num_deno_nan_divide_np, ndvi_cuda\n",
    "\n",
    "# os.chdir(r'/home/fruitspec-lab/FruitSpec/Code/roi/fsCounter/MHS')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from vision.tools.image_stitching import plot_2_imgs\n",
    "from vision.tools.camera import is_saturated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727846e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {0: (0, 100), 1: (25, 255), 2: (0, 150)},\n",
    "def thresh_channels(frame, xyz_frame, channels_thresh={0: (0, 175), 1: (10, 255), 2: (0, 200)},\n",
    "                    gree_minus_red_thres=(0, 0), gree_minus_blue_thres=(0, 0), vari_filter = 5, vndvi_filter = 0.35,\n",
    "                    depth_filter = (1, 5),show_imgs=False):\n",
    "    \"\"\"\n",
    "    Thresholds the input frame based on the given channel thresholds and green minus red thresholds.\n",
    "\n",
    "    Args:\n",
    "        frame (ndarray): The input frame to threshold.\n",
    "        channels_thresh (dict): A dictionary containing the channel indices as keys and a tuple of thresholds as values.\n",
    "        gree_minus_red_thres (tuple): A tuple containing the green minus red thresholds.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The thresholded frame.\n",
    "\n",
    "    \"\"\"\n",
    "    frame = np.copy(frame)\n",
    "    if np.sum(depth_filter) > 0:\n",
    "        if show_imgs:\n",
    "            frame_pre = frame.copy()\n",
    "        frame[xyz_frame[:,:,2] < depth_filter[0]] = 0\n",
    "        frame[xyz_frame[:,:,2] > depth_filter[1]] = 0\n",
    "        if show_imgs:\n",
    "            plot_2_imgs(frame_pre, frame, title = \"pre depth filter,    post filter\")        \n",
    "    if vari_filter + vndvi_filter > 0:\n",
    "        Red, Green, Blue = frame[:,:,0], frame[:,:,1], frame[:,:,2]\n",
    "#     if show_imgs:\n",
    "#         vndvi[~np.isfinite(vndvi)] = np.nanmin(vndvi)\n",
    "#         plot_2_imgs(vari, vndvi, title = \"Vari, vNDVI\")\n",
    "#         plot_2_imgs(vari > 0, vndvi > 0, title = \"Vari, vNDVI\")\n",
    "#         plot_2_imgs(vari > 1, vndvi > 0.3, title = \"Vari, vNDVI\")\n",
    "#         plot_2_imgs(vari > 2, vndvi > 0.31, title = \"Vari, vNDVI\")\n",
    "#         plot_2_imgs(vari > 3, vndvi > 0.32, title = \"Vari, vNDVI\")\n",
    "#         plot_2_imgs(vndvi > 0.35, vndvi > 0.33, title = \"vNDVI>0.35, vNDVI>0.33\")\n",
    "#         plot_2_imgs(vari > 4.5, vndvi > 0.34, title = \"Vari, vNDVI\")\n",
    "#         plot_2_imgs(vari >5, vndvi > 0.35, title = \"Vari, vNDVI\")\n",
    "#         plot_2_imgs(frame[:,:,0] - frame[:,:,2], frame[:,:,2] - frame[:,:,0])\n",
    "#         plot_2_imgs(frame[:,:,1] - frame[:,:,0], frame[:,:,1] - frame[:,:,2])\n",
    "#         plot_2_imgs(frame[:,:,1] - frame[:,:,0]>10, frame[:,:,1] - frame[:,:,2]>10)\n",
    "#         plot_2_imgs(frame[:,:,1] - frame[:,:,0]>50, frame[:,:,1] - frame[:,:,2]>50)\n",
    "#         plot_2_imgs(frame[:,:,1] - frame[:,:,0]>150, frame[:,:,1] - frame[:,:,2]>150)\n",
    "#         plot_2_imgs(frame[:,:,1] - frame[:,:,0]>250, frame[:,:,1] - frame[:,:,2]>250)\n",
    "    for channel, thresholds in channels_thresh.items():\n",
    "        if not np.sum(thresholds):\n",
    "            continue\n",
    "        chan = frame[:, :, channel]\n",
    "        valids = cv2.inRange(chan, thresholds[0], thresholds[1])\n",
    "        frame[np.where(valids==0)] = 0\n",
    "\n",
    "    if np.sum(gree_minus_red_thres) != 0:\n",
    "        diff = frame[:, :, 1] - frame[:, :, 0]\n",
    "        valids = cv2.inRange(diff, gree_minus_red_thres[0], gree_minus_red_thres[1])\n",
    "        if show_imgs:\n",
    "            frame_pre = frame.copy()\n",
    "        frame[np.where(valids==0)] = 0\n",
    "        if show_imgs:\n",
    "            plot_2_imgs(frame_pre, frame, title = \"prefilter g minus r,    post filter\")\n",
    "            \n",
    "    if np.sum(gree_minus_blue_thres) !=0:\n",
    "        diff = frame[:, :, 1] - frame[:, :, 2]\n",
    "        valids = cv2.inRange(diff, gree_minus_blue_thres[0], gree_minus_blue_thres[1])\n",
    "        if show_imgs:\n",
    "            frame_pre = frame.copy()\n",
    "        frame[np.where(valids==0)] = 0\n",
    "        if show_imgs:\n",
    "            plot_2_imgs(frame_pre, frame, title = \"prefilter g minus b,    post filter\")\n",
    "    \n",
    "    if vari_filter > 0:\n",
    "        vari = num_deno_nan_divide_np((Green - Red), (Green + Red - Blue))\n",
    "        vari[~np.isfinite(vari)] = 0\n",
    "        vari = np.clip(vari, -5,5)\n",
    "        if show_imgs:\n",
    "            frame_pre = frame.copy()\n",
    "        frame_copy = frame.copy()\n",
    "        frame_copy[vari >= vari_filter]= 0\n",
    "        frame[-int(frame.shape[0]/4):,:] = frame_copy[-int(frame.shape[0]/4):,:]\n",
    "        if show_imgs:\n",
    "            plot_2_imgs(frame_pre, frame, title = \"prefilter vari,    post filter\")\n",
    "            \n",
    "    if vndvi_filter > 0:\n",
    "        vndvi = 0.5268 * (Red**(-0.1294) * Green**(0.3389)* Blue**(-0.3118))\n",
    "        if show_imgs:\n",
    "            frame_pre = frame.copy()\n",
    "        frame[vndvi <= vndvi_filter] = 0\n",
    "        if show_imgs:\n",
    "            plot_2_imgs(frame_pre, frame, title = \"prefilter vndvi,    post filter\")\n",
    "            \n",
    "    if show_imgs:\n",
    "        if not vari_filter:\n",
    "            vari = num_deno_nan_divide_np((Green - Red), (Green + Red - Blue))\n",
    "            vari[~np.isfinite(vari)] = 0\n",
    "            vari = np.clip(vari, -5,5)   \n",
    "        if not vndvi_filter:\n",
    "            vndvi = 0.5268 * (Red**(-0.1294) * Green**(0.3389)* Blue**(-0.3118))\n",
    "        plot_2_imgs(vari < vari_filter, vndvi > vndvi_filter, title = \"vari filtered,    ndvi filtred\")\n",
    "    return cv2.threshold(frame[:, :, 1], 0, 255, cv2.THRESH_BINARY)[1] > 0\n",
    "\n",
    "\n",
    "def get_percent_seen(zed_frame, xyz_frame, coors, return_threshed=False, show_imgs=False):\n",
    "    \"\"\"\n",
    "    Calculates the percent of the frame that is covered by the input coordinates.\n",
    "\n",
    "    Args:\n",
    "        zed_frame (ndarray): The input frame.\n",
    "        coors (tuple): A tuple of coordinates (x1, y1, x2, y2) to exclude from the calculation.\n",
    "\n",
    "    Returns:\n",
    "        float: The percent of the frame that is covered by the input coordinates.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = coors\n",
    "    zed_threshed = thresh_channels(zed_frame, xyz_frame, show_imgs=show_imgs)\n",
    "    zed_threshed_cut = zed_threshed[:, x1:x2]\n",
    "    percent_seen = round(np.sum(zed_threshed_cut[y1:y2, :])/np.sum(zed_threshed_cut),2)\n",
    "    if return_threshed:\n",
    "        return percent_seen, zed_threshed_cut\n",
    "    return percent_seen\n",
    "\n",
    "def debug_percent_seen_batch(batch_fsi, batch_rgb_zed, batch_zed, frame_ids, b_align):\n",
    "    for jai, zed, zed_xyz, f_id, cors in zip(batch_fsi, batch_rgb_zed, batch_zed, frame_ids, b_align):\n",
    "        cors = [int(cor) for cor in cors[:4]]\n",
    "        x1, y1, x2, y2 = cors\n",
    "        zed_copy = zed.copy()\n",
    "        color = (0, 0, 255)\n",
    "        thickness = 2\n",
    "        percent_seen, zed_threshed = get_percent_seen(zed_copy, zed_xyz, cors[:4], True, True)\n",
    "        cv2.rectangle(zed_copy, (x1, y1), (x2, y2), color, thickness)\n",
    "        plot_2_imgs(jai, zed_copy, title=f_id, save_to=\"\", save_only=False, cv2_save=False, quick_save=False)\n",
    "        plot_2_imgs(zed_threshed, zed_copy, title=f\"frame: {f_id}, percent: {percent_seen}\",\n",
    "                    save_to=\"\", save_only=False, cv2_save=False, quick_save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcca91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_row(row_scan_path, min_slice_len, direction, tree_id, frames, shift):\n",
    "    adts_loader = None\n",
    "    validate_jai_zed_json(row_scan_path)\n",
    "    validate_slice_data(row_scan_path, min_slice_len=min_slice_len, direction=direction)\n",
    "    metadata, _ = get_metadata(row_scan_path)\n",
    "    fe, adts_loader, batch_size = init_fe_obj(row_scan_path, tree_id, adts_loader, False, direction)\n",
    "    n_batchs = len(frames) // batch_size\n",
    "    for i in tqdm(range(n_batchs)):\n",
    "        frame_ids = frames[i * batch_size: (i + 1) * batch_size]\n",
    "        batch_res = adts_loader.load_batch(frame_ids, shift)\n",
    "        batch_fsi, batch_zed, batch_jai_rgb, batch_rgb_zed, batch_tracker, batch_slicer, frame_ids, b_align, b_jai_translation = batch_res\n",
    "        debug_percent_seen_batch(batch_fsi, batch_rgb_zed, batch_zed, frame_ids, b_align)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cafd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_slice_len=5\n",
    "direction=\"left\"\n",
    "frames = [str(num) for num in range(100,110)]\n",
    "tree_id = 0\n",
    "shift = 0\n",
    "os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(new_directory)\n",
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/BEERAMU0/220823/row_107/1\"\n",
    "frames = [str(num) for num in range(100,109)]\n",
    "run_on_row(row_scan_path, min_slice_len, direction, tree_id, frames, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/ORSCHIST/230813/row_6/1\"\n",
    "frames = [str(num) for num in range(250,259)]\n",
    "run_on_row(row_scan_path, min_slice_len, direction, tree_id, frames, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/MICHAL22/240723/row_102/2\"\n",
    "frames = [str(num) for num in range(200,209)]\n",
    "run_on_row(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/RAUSTENB/060723/row_2/1\"\n",
    "frames = [str(num) for num in range(400,409)]\n",
    "run_on_row(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5645e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/MOTCHA/MEIRAVHA/230723/row_101/1\"\n",
    "frames = [str(num) for num in range(100,109)]\n",
    "run_on_row(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/PROPAL/M7XXXXXX/250323/row_23/1\"\n",
    "frames = [str(num) for num in range(1000,1009)]\n",
    "run_on_row(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b5a9a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/PROPAL/FUKUMOTO/260323/row_22/1\"\n",
    "frames = [str(num) for num in range(2000, 2009)]\n",
    "run_on_row(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c68382",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_scan_path = \"/media/fruitspec-lab/cam175/customers_new/PROPAL/2018XXXX/230323/row_62/1\"\n",
    "frames = [str(num) for num in range(1500, 1509)]\n",
    "run_on_row(row_scan_path, min_slice_len, \"right\", tree_id, frames, shift)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FsCounter",
   "language": "python",
   "name": "fscounter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
