{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/fruitspec-lab/FruitSpec/Code/fsCounter')\n",
    "from omegaconf import OmegaConf\n",
    "import pyzed.sl as sl\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import kornia as K\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "from vision.misc.help_func import get_repo_dir, scale_dets, validate_output_path, scale\n",
    "from vision.depth.zed.svo_operations import get_frame, get_depth, get_point_cloud, get_dimensions, sl_get_dimensions\n",
    "\n",
    "repo_dir = get_repo_dir()\n",
    "sys.path.append(os.path.join(repo_dir, 'vision', 'detector', 'yolo_x'))\n",
    "\n",
    "from vision.pipelines.detection_flow import counter_detection\n",
    "from vision.pipelines.misc.filters import filter_by_distance, filter_by_size, filter_by_height, sort_out\n",
    "from vision.tracker.fsTracker.score_func import compute_dist_on_vec\n",
    "from vision.data.results_collector import ResultsCollector\n",
    "from vision.tools.translation import translation as T\n",
    "from vision.tools.camera import is_sturated\n",
    "from vision.tools.color import get_hue\n",
    "from vision.tools.video_wrapper import video_wrapper\n",
    "from vision.tools.image_stitching import plot_2_imgs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kornia as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = get_repo_dir()\n",
    "pipeline_config = \"/home/fruitspec-lab/FruitSpec/Code/fsCounter/vision/pipelines/config/pipeline_config.yaml\"\n",
    "runtime_config = \"/home/fruitspec-lab/FruitSpec/Code/fsCounter/vision/pipelines/config/runtime_config.yaml\"\n",
    "cfg = OmegaConf.load(pipeline_config)\n",
    "args = OmegaConf.load(runtime_config)\n",
    "\n",
    "validate_output_path(args.output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint from /home/fruitspec-lab/FruitSpec/weights/Run_6_Dec_2022_1Class_aug_tasqV2/best_ckpt.pth\n",
      "loaded checkpoint done.\n",
      "Inferencing on /home/fruitspec-lab/Downloads/0.8m1sts/ZED_1.svo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detector = counter_detection(cfg, args)\n",
    "results_collector = ResultsCollector(rotate=args.rotate)\n",
    "translation = T(cfg.translation.translation_size, cfg.translation.dets_only, cfg.translation.mode)\n",
    "\n",
    "cam = video_wrapper(args.movie_path, args.rotate, args.depth_minimum, args.depth_maximum)\n",
    "\n",
    "# Read until video is completed\n",
    "print(f'Inferencing on {args.movie_path}\\n')\n",
    "number_of_frames = cam.get_number_of_frames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_path = \"/home/fruitspec-lab/Downloads/0.8m1sts/output/measures.csv\"\n",
    "measures_frame = pd.read_csv(measures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_grid(images, nrows, ncols, titles=None, figsize=None, xlabels=None, ylabels=None, cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Plots a grid of images using matplotlib.\n",
    "\n",
    "    Parameters:\n",
    "    images (list): A list of numpy arrays representing the images to be plotted.\n",
    "    nrows (int): The number of rows in the grid.\n",
    "    ncols (int): The number of columns in the grid.\n",
    "    titles (list, optional): A list of strings representing the titles of the images. Must have the same length as images.\n",
    "    figsize (tuple, optional): A tuple representing the size of the figure. Defaults to (ncols * 5, nrows * 5).\n",
    "    xlabels (list, optional): A list of strings representing the x-axis labels for each image. Must have the same length as images.\n",
    "    ylabels (list, optional): A list of strings representing the y-axis labels for each image. Must have the same length as images.\n",
    "    cmap (str, optional): The color map to use when plotting the images. Defaults to 'viridis'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    if isinstance(figsize, type(None)):\n",
    "        figsize = (ncols * 5, nrows * 5)\n",
    "    titles, xlabels, ylabels = (np.full(n_images, \"\") if isinstance(titles, type(None)) else arr\n",
    "                                for arr in [titles, xlabels, ylabels])\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        image = images[i]\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(titles[i])\n",
    "        ax.set_xlabel(xlabels[i])\n",
    "        ax.set_ylabel(ylabels[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_real_world_dims_with_correction(depth_map, fx = 1065.98388671875, fy = 1065.98388671875, resized = True):\n",
    "    \"\"\"\n",
    "    calculates each pixel size based on trigo\n",
    "    :param depth_map: distance_map to each point or an empty string\n",
    "    :return: size for each pixel\n",
    "    \"\"\"\n",
    "    pic_size = depth_map.shape\n",
    "    if resized:\n",
    "        resize_fator_x = 1080/pic_size[0]\n",
    "        resize_fator_y = 1920/pic_size[1]\n",
    "    else:\n",
    "        resize_fator_x = 1\n",
    "        resize_fator_y = 1\n",
    "    x0 = pic_size[1] /2\n",
    "    y0 = pic_size[0] /2\n",
    "    pixel_mm = 0.002\n",
    "    focal_len = (fx + fy) / 2 * pixel_mm\n",
    "    x_range = np.arange(1, pic_size[1]+1)\n",
    "    X_pix_dist_from_center = np.abs(np.array([x_range for i in range(pic_size[0])]) - x0)\n",
    "    X_mm_dist_from_center = (X_pix_dist_from_center * (X_pix_dist_from_center+1)*(pixel_mm**2))\n",
    "    beta = np.arctan(0.001/(focal_len + (X_mm_dist_from_center/focal_len)))\n",
    "    gamma = np.arctan((X_pix_dist_from_center+1)*pixel_mm/focal_len)\n",
    "    size_x = (np.tan(gamma) - np.tan(gamma-beta))*depth_map*2*resize_fator_x\n",
    "    size_y = (np.tan(gamma) - np.tan(gamma-beta))*depth_map*2*resize_fator_y\n",
    "    return size_x, size_y, size_x*size_y\n",
    "\n",
    "def get_pix_size(depth, box, fx = 1065.98388671875, fy = 1065.98388671875,\n",
    "                 pixel_mm = 0.0002, org_size = np.array([1920,1080])):\n",
    "    \"\"\"\n",
    "    Calculates the size of a pixel in millimeters given a distance from the camera and the intrinsic parameters of the camera.\n",
    "\n",
    "    Args:\n",
    "        depth (float): The depth from the camera to the object in meters.\n",
    "        box (list): ROI for pixel size int hte following format: x1,y1,x2,y2.\n",
    "        fx (float): The focal length of the camera in the x direction in pixels. Default is 1065.98388671875.\n",
    "        fy (float): The focal length of the camera in the y direction in pixels. Default is 1065.98388671875.\n",
    "        pixel_mm (float): The size of a pixel in millimeters. Default is 0.002.\n",
    "        org_size (ndarray): The size of the image in pixels. Default is np.array([1920, 1080]).\n",
    "\n",
    "    Returns:\n",
    "        size_pix (float): The size of a pixel\n",
    "    \"\"\"\n",
    "    x1,y1,x2,y2 = box\n",
    "    y0, x0 = org_size/2\n",
    "    focal_len = (fx + fy) / 2 * pixel_mm\n",
    "    x_range = np.arange(x1, x2+1)\n",
    "    x_pix_dist_from_center = np.abs(np.array([x_range for i in range(y2-y1)]) - x0)\n",
    "    x_mm_dist_from_center = (x_pix_dist_from_center * (x_pix_dist_from_center+1)*(pixel_mm**2))\n",
    "    beta = np.arctan(0.001/(focal_len + (x_mm_dist_from_center/focal_len)))\n",
    "    gamma = np.arctan((x_mm_dist_from_center+1)*pixel_mm/focal_len)\n",
    "    size_pix = (np.tan(gamma) - np.tan(gamma-beta))*depth*2\n",
    "    return size_pix\n",
    "\n",
    "\n",
    "def cut_center_of_box(image, margin=0.05):\n",
    "    \"\"\"\n",
    "    Cuts the center of the box.\n",
    "    \n",
    "    Args:\n",
    "    - image: A 3D Numpy array representing a cropped xyz image.\n",
    "    - margin: A float representing the percentage of margin to remove from the center of the image.\n",
    "\n",
    "    Returns:\n",
    "    - A 3D Numpy array representing the cropped image with the outside of the box removed.\n",
    "    \"\"\"\n",
    "    t, l, (b, r) = 0 ,0, image.shape[:2]\n",
    "    y_max, x_max = image.shape[:2]\n",
    "    h_m = int((b-t)*margin)\n",
    "    w_m = int((r-l)*margin)\n",
    "    cut_box = image[max(0, t+h_m):min(y_max, b-h_m), max(0, l+w_m):min(x_max, r-w_m)]\n",
    "    return cut_box\n",
    "\n",
    "\n",
    "def xyz_center_of_box(image, method=\"median\"):\n",
    "    \"\"\"\n",
    "    Calculates the median or mean x, y, and z coordinates of the fruit.\n",
    "\n",
    "    Args:\n",
    "    - image: A 3D Numpy array representing a cropped xyz image.\n",
    "    - method: A string representing the method to use to calculate the center of the fruit. Must be either \"median\" or \"mean\".\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of floats representing the x, y, and z coordinates of the center of the fruit.\n",
    "    \"\"\"\n",
    "    if method==\"median\":\n",
    "        cut_box = cut_center_of_box(image, 0.025)\n",
    "        x_median = np.nanmedian(cut_box[:, :, 0])\n",
    "        y_median = np.nanmedian(cut_box[:, :, 1])\n",
    "        z_median = np.nanmedian(cut_box[:, :, 2])\n",
    "    elif method==\"mean\":\n",
    "        cut_box = cut_center_of_box(image, 0.4)\n",
    "        x_median = np.nanmean(cut_box[:, :, 0])\n",
    "        y_median = np.nanmean(cut_box[:, :, 1])\n",
    "        z_median = np.nanmean(cut_box[:, :, 2])\n",
    "    else: # calculates only on the edge of the cut box\n",
    "        cut_box = cut_center_of_box(image, 0.25).copy()\n",
    "        if cut_box.shape[0] > 10 and cut_box.shape[1] > 10:\n",
    "            cut_box[5:-5,5:-5] = np.nan\n",
    "        x_median = np.nanmedian(cut_box[:, :, 0])\n",
    "        y_median = np.nanmedian(cut_box[:, :, 1])\n",
    "        z_median = np.nanmedian(cut_box[:, :, 2])\n",
    "    return x_median, y_median, z_median\n",
    "\n",
    "\n",
    "def dist_to_box_center(image, method=\"median\"):\n",
    "    \"\"\"\n",
    "    Calculates the distance from the camera to the center of the fruit.\n",
    "\n",
    "    Args:\n",
    "    - image: A 3D Numpy array representing a cropped xyz image.\n",
    "    - method: A string representing the method to use to calculate the center of the fruit. Must be either \"median\" or \"mean\".\n",
    "\n",
    "    Returns:\n",
    "    - A float representing the distance from the camera to the center of the fruit.\n",
    "    \"\"\"\n",
    "    return np.sum(np.array(list(xyz_center_of_box(image, method)))**2)\n",
    "\n",
    "def depth_to_box_center(image, method=\"median\"):\n",
    "    \"\"\"\n",
    "    Calculates the depth from the camera to the center of the fruit.\n",
    "\n",
    "    Args:\n",
    "    - image: A 3D Numpy array representing a cropped xyz image.\n",
    "    - method: A string representing the method to use to calculate the center of the fruit. Must be either \"median\" or \"mean\".\n",
    "\n",
    "    Returns:\n",
    "    - A float representing the depth from the camera to the center of the fruit.\n",
    "    \"\"\"\n",
    "    return xyz_center_of_box(image, method)[2]\n",
    "\n",
    "def get_dims_w_pixel_size(pc_img, box, center_method=\"median\"):\n",
    "    \"\"\"\n",
    "    Calculates the width and height of a 2D bounding box in millimeters, based on the pixel size of the image.\n",
    "\n",
    "    Args:\n",
    "    - pc_img: A 3D Numpy array representing a point cloud image.\n",
    "    - box: A tuple of integers representing the (x1, y1, x2, y2) coordinates of the bounding box.\n",
    "    - center_method: A string representing the method to use to calculate the center of the fruit. Must be either \"median\" or \"mean\".\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of floats representing the width and height of the bounding box in millimeters.\n",
    "    \"\"\"\n",
    "    dist = depth_to_box_center(pc_img, center_method)\n",
    "    size_pix = get_pix_size(dist, box)\n",
    "    width = np.mean(np.sum(size_pix,axis = 0))\n",
    "    height = np.mean(np.sum(size_pix,axis = 1))\n",
    "    return width, height \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_id_frames(measures_frame, track_id):\n",
    "    \"\"\"\n",
    "    Returns a numpy array of frames associated with a given track ID.\n",
    "\n",
    "    Parameters:\n",
    "    measures_frame (pandas.DataFrame): A dataframe containing measurements data.\n",
    "    track_id (int): The ID of the track to retrieve frames for.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 1-dimensional array of frames associated with the given track ID.\n",
    "    \"\"\"\n",
    "    return measures_frame[measures_frame[\"track_id\"] == track_id][\"frame\"].values\n",
    "\n",
    "def get_track_id_boxes(measures_frame, track_id):\n",
    "    \"\"\"\n",
    "    Returns a numpy array of bounding boxes associated with a given track ID.\n",
    "\n",
    "    Parameters:\n",
    "    measures_frame (pandas.DataFrame): A dataframe containing measurements data.\n",
    "    track_id (int): The ID of the track to retrieve bounding boxes for.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 2-dimensional array of bounding boxes associated with the given track ID.\n",
    "        Each row contains the x1, y1, x2, y2 coordinates of a bounding box in the format [x1, y1, x2, y2].\n",
    "    \"\"\"\n",
    "    return measures_frame[measures_frame[\"track_id\"] == track_id][[\"x1\", \"y1\", \"x2\", \"y2\"]].values\n",
    "\n",
    "def validate_bbox(crop, rgb_img):\n",
    "    \"\"\"\n",
    "    Validates the given bounding box coordinates and ensures that they fall within the dimensions of the RGB image.\n",
    "\n",
    "    Parameters:\n",
    "    crop (tuple): A tuple containing the coordinates of the bounding box in the format (x1, y1, x2, y2).\n",
    "        x1 and y1 are the coordinates of the top-left corner of the bounding box, and x2 and y2 are the coordinates of the bottom-right corner.\n",
    "    rgb_img (numpy.ndarray): A numpy array representing the RGB image.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the validated bounding box coordinates in the format (x1, y1, x2, y2).\n",
    "        The returned coordinates ensure that the bounding box falls entirely within the dimensions of the RGB image.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = crop\n",
    "    x1 = max(x1, 0)\n",
    "    y1 = max(y1, 0)\n",
    "    h, w = rgb_img.shape[:2]\n",
    "    x2 = min(x2, w-1)\n",
    "    y2 = min(y2, h-1)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def get_track_id_images(measures_frame, track_id, args):\n",
    "    cam = video_wrapper(args.movie_path, args.rotate, args.depth_minimum, args.depth_maximum)\n",
    "    frame_numbers = get_track_id_frames(measures_frame, track_id)\n",
    "    boxes = get_track_id_boxes(measures_frame, track_id)\n",
    "    rgb_images, pc_images = [], []\n",
    "    for i in tqdm(range(len(frame_numbers))):\n",
    "        frame, crop = frame_numbers[i], boxes[i]\n",
    "        rgb_img, _, pc_img = cam.get_zed(frame)\n",
    "        x1,y1,x2,y2 = validate_bbox(crop, rgb_img)\n",
    "        rgb_images.append(rgb_img[y1:y2,x1:x2])\n",
    "        pc_images.append(pc_img[y1:y2,x1:x2])\n",
    "    cam.close()\n",
    "    return rgb_images, pc_images\n",
    "\n",
    "def kde_filtering(centers, thresh=0.5):\n",
    "    \"\"\"\n",
    "    Applies a Kernel Density Estimation (KDE) filtering on a set of 3D points.\n",
    "\n",
    "    Args:\n",
    "        centers (np.ndarray): A numpy array of shape (n, 3) representing the 3D coordinates of the points to filter.\n",
    "        thresh (float): A threshold value to filter out points with low density. Default is 0.5.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A numpy array of shape (n, 3) where each filtered 3D points is replaced with np.nan\n",
    "    \"\"\"\n",
    "    finite_logical = np.all(np.isfinite(centers), axis=1)\n",
    "    if not sum(finite_logical):\n",
    "        return centers\n",
    "    finite_centers = centers[finite_logical].copy()\n",
    "    kernel = gaussian_kde(finite_centers.T)\n",
    "    points_density = np.full(len(centers), np.nan)\n",
    "    points_density[finite_logical] = kernel(finite_centers.T)\n",
    "    points_density = points_density/np.nansum(points_density)\n",
    "    filtered_center = centers.copy()\n",
    "    filtered_center[points_density <thresh/ len(finite_logical)] = np.nan\n",
    "    return filtered_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb_images, pc_images = get_track_id_images(measures_frame, 7)\n",
    "# plot_2_imgs(rgb_images[0], pc_images[0][:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for track_id in [6,7,8,28]:\n",
    "#     print(track_id)\n",
    "#     frame_numbers = get_track_id_frames(measures_frame, track_id)\n",
    "#     boxes = get_track_id_boxes(measures_frame, track_id)\n",
    "#     rgb_images, pc_images = [], []\n",
    "#     for frame, crop in tqdm(zip(frame_numbers, boxes)):\n",
    "#         rgb_img, _, pc_img = cam.get_zed(frame)\n",
    "#         x1,y1,x2,y2 = validate_bbox(crop, rgb_img)\n",
    "#         rgb_images.append(rgb_img[y1:y2,x1:x2])\n",
    "#         pc_images.append(pc_img[y1:y2,x1:x2])\n",
    "#     plot_image_grid(rgb_images,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_xyz_outliers(crop, nstd=1.5, as_points=True):\n",
    "    \"\"\"\n",
    "    Filters out the outliers from the 3D points in the given crop.\n",
    "\n",
    "    Args:\n",
    "        crop (ndarray): A numpy array of shape (height, width, 3) containing the 3D points.\n",
    "        nstd (float): The number of standard deviations to consider for defining the range of valid values.\n",
    "        as_points (bool): Whether to return the filtered 3D points as an array of points or as an array of the same shape\n",
    "            as the input crop.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: A numpy array of filtered 3D points. If as_points is True, this is a numpy array of shape (n, 3),\n",
    "            where n is the number of valid 3D points. Otherwise, it is a numpy array of the same shape as the input crop.\n",
    "    \"\"\"\n",
    "    centers = crop.reshape(-1, 3)\n",
    "    filtered_center = centers.copy()\n",
    "    for channel in [0, 1, 2]:\n",
    "        channel_vals = centers[:, channel]\n",
    "        max_val = np.abs(np.nanmedian(channel_vals) + nstd * np.nanstd(channel_vals))\n",
    "        filtered_center[np.abs(channel_vals) > max_val] = np.nan\n",
    "    if as_points:\n",
    "        return filtered_center\n",
    "    return filtered_center.reshape(crop.shape)\n",
    "\n",
    "\n",
    "def ellipsoid_fit(filtered_center):\n",
    "    \"\"\"\n",
    "    Fits an ellipsoid to a set of 3D points using least squares estimation.\n",
    "\n",
    "    Args:\n",
    "    - filtered_center (numpy array): An N x 3 array of N 3D points in the form (x, y, z).\n",
    "\n",
    "    Returns:\n",
    "    - radius (float): The radius of the fitted ellipsoid.\n",
    "    - semi_axis_1 (float): The length of the semi-major axis of the ellipsoid.\n",
    "    - semi_axis_2 (float): The length of the semi-intermediate axis of the ellipsoid.\n",
    "    - semi_axis_3 (float): The length of the semi-minor axis of the ellipsoid.\n",
    "    \"\"\"\n",
    "    filtered_center[np.abs(filtered_center) > 2] = np.nan\n",
    "    A = np.column_stack([filtered_center, np.ones(len(filtered_center))])\n",
    "    good_rows = np.all(np.isfinite(A), axis=1)\n",
    "    A = A[good_rows]\n",
    "\n",
    "    #   Assemble the f matrix\n",
    "    f = np.zeros((len(A),1))\n",
    "    f[:,0] = np.sum(A[:,:3]**2, axis = 1)\n",
    "    C, residules, rank, singval = np.linalg.lstsq(A,f)\n",
    "    C = np.abs(C)\n",
    "    #   solve for the radius\n",
    "    t = (C[0]*C[0])+(C[1]*C[1])+(C[2]*C[2])+C[3]\n",
    "    radius = np.sqrt(t)\n",
    "    # channels are switched\n",
    "    return radius, np.sqrt(C[1]), np.sqrt(C[0]), np.sqrt(C[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "def ellipsoid_fit_ransac(filtered_center, num_iterations=100, inlier_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Fits an ellipsoid to a set of 3D points using RANSAC.\n",
    "\n",
    "    Args:\n",
    "    - filtered_center (numpy array): An N x 3 array of N 3D points in the form (x, y, z).\n",
    "    - num_iterations (int): The number of iterations to run RANSAC for.\n",
    "    - inlier_threshold (float): The maximum distance from a point to the fitted ellipsoid to be considered an inlier.\n",
    "\n",
    "    Returns:\n",
    "    - radius (float): The radius of the fitted ellipsoid.\n",
    "    - semi_axis_1 (float): The length of the semi-major axis of the ellipsoid.\n",
    "    - semi_axis_2 (float): The length of the semi-intermediate axis of the ellipsoid.\n",
    "    - semi_axis_3 (float): The length of the semi-minor axis of the ellipsoid.\n",
    "    \"\"\"\n",
    "    filtered_center[np.abs(filtered_center) > 2] = np.nan\n",
    "    A = np.column_stack([filtered_center, np.ones(len(filtered_center))])\n",
    "    good_rows = np.all(np.isfinite(A), axis=1)\n",
    "    A = A[good_rows]\n",
    "    if len(A) < 5:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    f = np.zeros((len(A),1))\n",
    "    f[:,0] = np.sum(A[:,:3]**2, axis = 1)\n",
    "\n",
    "    model = RANSACRegressor(estimator=None, residual_threshold=inlier_threshold, max_trials=num_iterations)\n",
    "    model.fit(A,f)\n",
    "\n",
    "    # Extract the coefficients of the fitted ellipsoid\n",
    "    coef = model.estimator_.coef_[0]\n",
    "    C = np.abs(np.concatenate([coef[:3], [1], coef[3:]]))\n",
    "\n",
    "    #   solve for the radius\n",
    "    t = (C[0]*C[0])+(C[1]*C[1])+(C[2]*C[2])+C[3]\n",
    "    radius = np.sqrt(t)\n",
    "\n",
    "    # channels are switched\n",
    "    return radius, np.sqrt(C[1]), np.sqrt(C[0]), np.sqrt(C[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                   | 0/107 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'width' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m         pc_crop \u001b[38;5;241m=\u001b[39m pc_img[y1:y2, x1:x2,:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         filtered_center = kde_filtering(pc_crop[:,:,:3].reshape(-1,3))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         _, width, height, z_w = ellipsoid_fit_ransac(filtered_center)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#         if width > 200 or height > 200 or z_w > 200: #if fruits are too big its probably due to noise\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#             width, height, z_w = np.nan, np.nan, np.nan\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         ellps_w\u001b[38;5;241m.\u001b[39mappend(\u001b[43mwidth\u001b[49m), ellps_h\u001b[38;5;241m.\u001b[39mappend(height), ellps_z\u001b[38;5;241m.\u001b[39mappend(z_w)\n\u001b[1;32m     18\u001b[0m         width, height \u001b[38;5;241m=\u001b[39m get_dims_w_pixel_size(pc_img, [x1,y1,x2,y2], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m         pix_size_w_mean\u001b[38;5;241m.\u001b[39mappend(width), pix_size_h_mean\u001b[38;5;241m.\u001b[39mappend(height)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'width' is not defined"
     ]
    }
   ],
   "source": [
    "for track_id in [6,7,12,28]:\n",
    "    cam = video_wrapper(args.movie_path, args.rotate, args.depth_minimum, args.depth_maximum)\n",
    "    frame_numbers = get_track_id_frames(measures_frame, track_id)\n",
    "    boxes = get_track_id_boxes(measures_frame, track_id)\n",
    "    ellps_w, ellps_h, ellps_z = [], [], []\n",
    "    pix_size_w_mean, pix_size_h_mean = [], []\n",
    "    pix_size_w_med, pix_size_h_med = [], []\n",
    "    for i in tqdm(range(len(frame_numbers))):\n",
    "        frame, box = frame_numbers[i], boxes[i]\n",
    "        rgb_img, _, pc_img = cam.get_zed(frame)\n",
    "        x1,y1,x2,y2 = validate_bbox(box, rgb_img)\n",
    "        pc_crop = pc_img[y1:y2, x1:x2,:3]\n",
    "#         filtered_center = kde_filtering(pc_crop[:,:,:3].reshape(-1,3))\n",
    "#         _, width, height, z_w = ellipsoid_fit_ransac(filtered_center)\n",
    "#         if width > 200 or height > 200 or z_w > 200: #if fruits are too big its probably due to noise\n",
    "#             width, height, z_w = np.nan, np.nan, np.nan\n",
    "        ellps_w.append(width), ellps_h.append(height), ellps_z.append(z_w)\n",
    "        width, height = get_dims_w_pixel_size(pc_img, [x1,y1,x2,y2], \"mean\")\n",
    "        pix_size_w_mean.append(width), pix_size_h_mean.append(height)\n",
    "        width, height = get_dims_w_pixel_size(pc_img, [x1,y1,x2,y2], \"median\")\n",
    "        pix_size_w_med.append(width), pix_size_h_med.append(height)\n",
    "\n",
    "    plt.imshow(rgb_img[y1:y2, x1:x2])\n",
    "    plt.title(track_id)\n",
    "    plt.show()\n",
    "    print(np.nanmean(ellps_w), np.nanstd(ellps_w), np.nanmean(ellps_h), np.nanstd(ellps_h), np.nanmean(ellps_z), np.nanstd(ellps_z)\n",
    "     ,np.nanmean(pix_size_w_mean), np.nanstd(pix_size_w_mean),np.nanmean(pix_size_h_mean), np.nanstd(pix_size_h_mean)\n",
    "    ,np.nanmean(pix_size_w_med), np.nanstd(pix_size_w_med),np.nanmean(pix_size_h_med), np.nanstd(pix_size_h_med))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = 5\n",
    "cam = video_wrapper(args.movie_path, args.rotate, args.depth_minimum, args.depth_maximum)\n",
    "frame_numbers = get_track_id_frames(measures_frame, track_id)\n",
    "boxes = get_track_id_boxes(measures_frame, track_id)\n",
    "ellps_w, ellps_h, ellps_z = [], [], []\n",
    "pix_size_w_mean, pix_size_h_mean = [], []\n",
    "pix_size_w_med, pix_size_h_med = [], []\n",
    "i = len(frame_numbers) -1\n",
    "frame, box = frame_numbers[i], boxes[i]\n",
    "rgb_img, _, pc_img = cam.get_zed(frame)\n",
    "x1,y1,x2,y2 = validate_bbox(box, rgb_img)\n",
    "pc_crop = pc_img[y1:y2, x1:x2,:3]\n",
    "plt.imshow(rgb_img[y1:y2, x1:x2])\n",
    "plt.title(track_id)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_box_pc = cut_center_of_box(pc_crop, 0.1)\n",
    "cut_box_rgb = cut_center_of_box(rgb_img[y1:y2, x1:x2], 0.1)\n",
    "plot_2_imgs(cut_box_pc[:, :, 2], cut_box_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sobol(det_crop, plot_change=False):\n",
    "    \"\"\"\n",
    "    applies sobol filterning on image\n",
    "    :param det_crop: image to apply filter on\n",
    "    :param plot_change: flag to show the image after applying sobol\n",
    "    :return: image after sobol filtering\n",
    "    \"\"\"\n",
    "    torch_img = K.utils.image_to_tensor(det_crop)\n",
    "    torch_img = torch_img[None, ...].float() / 255.\n",
    "    torch_img = K.enhance.adjust_contrast(torch_img, 0.5)\n",
    "    torch_img_gray = K.color.rgb_to_grayscale(torch_img)\n",
    "    processed_img = K.filters.sobel(torch_img_gray, True, 1e-3)  # BxCx2xHxW\n",
    "    if plot_change:\n",
    "        plot_2_imgs(det_crop, processed_img.detach().numpy()[0, 0] > 0.05)\n",
    "    return processed_img\n",
    "apply_sobol(rgb_img[y1:y2, x1:x2], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images, pc_images = get_track_id_images(measures_frame, 5, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "h = []\n",
    "for track_id in range(len(pc_images)):\n",
    "    pc_img = pc_images[track_id]\n",
    "    box = get_track_id_boxes(measures_frame, 5)[track_id]\n",
    "    wid,hei = get_dims_w_pixel_size(pc_img, box, \"mean\")\n",
    "    w.append(wid), h.append(hei)\n",
    "np.mean(w), np.mean(h), np.std(w), np.std(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_images[-1][30,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_images[-1][30,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = pc_images[-1][30,:,2].flatten()\n",
    "sns.kdeplot(arr)\n",
    "plt.vlines(np.nanmedian(arr), 0,17.5,color = \"black\")\n",
    "plt.vlines(np.nanmedian(arr) + 2*arr.std(),0,17.5,color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pc_images[-1][:,:,:3].reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(-centers[:, 2], -centers[:, 0], -centers[:, 1])\n",
    "# for i, label in enumerate(fruit_3d_space.keys()):\n",
    "#     ax.text(-centers[i, 2], -centers[i, 0], -centers[i, 1], '%s' % (str(label)), size=10, zorder=1,\n",
    "#             color='k')\n",
    "ax.set_xlabel('z')\n",
    "ax.set_ylabel('x')\n",
    "ax.set_zlabel('y')\n",
    "ax.view_init(0,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "def measure(n):\n",
    "    \"Measurement model, return two coupled measurements.\"\n",
    "    m1 = np.random.normal(size=n)\n",
    "    m2 = np.random.normal(scale=0.5, size=n)\n",
    "    return m1+m2, m1-m2\n",
    "m1, m2 = measure(2000)\n",
    "xmin = m1.min()\n",
    "xmax = m1.max()\n",
    "ymin = m2.min()\n",
    "ymax = m2.max()\n",
    "X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "values = np.vstack([m1, m2])\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite_centers = centers[np.all(np.isfinite(centers),axis = 1)]\n",
    "kernel = gaussian_kde(finite_centers.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(kernel(finite_centers.T)/np.sum(kernel(finite_centers.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0001*len(finite_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rgb_images)):\n",
    "    rgb_img = rgb_images[i]\n",
    "    # plt.imshow(rgb_img)\n",
    "    centers = pc_images[i][:,:,:3].reshape(-1,3)\n",
    "    filtered_center = kde_filtering(centers)\n",
    "    # max_z = min(np.abs(np.nanmedian(centers[:,2]) + 2 * np.nanstd(centers[:,2])),1.1)\n",
    "    # filtered_center[np.abs(centers[:,2]) > max_z] = np.nan\n",
    "    # filtered_center[np.abs(centers[:,1]) > np.abs(np.nanmedian(centers[:,1]) + 2 * np.nanstd(centers[:,1]))] = np.nan\n",
    "    # filtered_center[np.abs(centers[:,0]) > np.abs(np.nanmedian(centers[:,0]) + 2* np.nanstd(centers[:,0]))] = np.nan\n",
    "    filtere_rgb = rgb_img.copy()\n",
    "    filtere_rgb[np.isnan(filtered_center.reshape(rgb_img.shape))] = 0\n",
    "    plot_2_imgs(rgb_img, filtere_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "rgb_img = rgb_images[-4]\n",
    "# plt.imshow(rgb_img)\n",
    "centers = pc_images[-4][:,:,:3].reshape(-1,3)\n",
    "finite_centers = centers[np.all(np.isfinite(centers),axis = 1)].copy()\n",
    "kernel = gaussian_kde(finite_centers.T)\n",
    "points_density = np.array([])\n",
    "for point in centers:\n",
    "    if not np.sum(np.isnan(point)):\n",
    "        points_density = np.append(points_density, kernel(point))\n",
    "    else:\n",
    "        points_density = np.append(points_density, np.nan)\n",
    "\n",
    "points_density = points_density/np.nansum(points_density)\n",
    "filtered_center = finite_centers.copy()\n",
    "filtered_center[points_density <0.5/ len(finite_centers)] = np.nan\n",
    "# max_z = min(np.abs(np.nanmedian(centers[:,2]) + 2 * np.nanstd(centers[:,2])),1.1)\n",
    "# filtered_center[np.abs(centers[:,2]) > max_z] = np.nan\n",
    "# filtered_center[np.abs(centers[:,1]) > np.abs(np.nanmedian(centers[:,1]) + 2 * np.nanstd(centers[:,1]))] = np.nan\n",
    "# filtered_center[np.abs(centers[:,0]) > np.abs(np.nanmedian(centers[:,0]) + 2* np.nanstd(centers[:,0]))] = np.nan\n",
    "filtere_rgb = rgb_img.copy()\n",
    "filtere_rgb[np.isnan(filtered_center.reshape(rgb_img.shape))] = 0\n",
    "plot_2_imgs(rgb_img, filtere_rgb)\n",
    "def plot_3d_scatter(angle1, angle2, angle3):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter3D(-filtered_center[:, 2], -filtered_center[:, 1], -filtered_center[:, 0],s = 1)\n",
    "    ax.set_xlabel('z')\n",
    "    ax.set_ylabel('x')\n",
    "    ax.set_zlabel('y')\n",
    "    ax.view_init(angle1, angle2, angle3)\n",
    "    plt.show()\n",
    "    \n",
    "# define the sliders for the viewing angles\n",
    "angle1_slider = widgets.FloatSlider(min=-180, max=180, step=1, value=0)\n",
    "angle2_slider = widgets.FloatSlider(min=-180, max=180, step=1, value=0)\n",
    "angle3_slider = widgets.FloatSlider(min=-180, max=180, step=1, value=0)\n",
    "\n",
    "# create the interactive plot\n",
    "interactive_plot = interact(plot_3d_scatter, angle1=angle1_slider, angle2=angle2_slider, angle3 = angle3_slider)\n",
    "\n",
    "# display the interactive plot\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def ellipsoid_fit(filtered_center):\n",
    "    spX=filtered_center[:,0]\n",
    "    spY=filtered_center[:,1]\n",
    "    spZ=filtered_center[:,2]\n",
    "    falut_rows = np.any(np.isnan(np.column_stack([spX,spY,spZ])), axis=1)\n",
    "    spX,spY,spZ = spX[~falut_rows],spY[~falut_rows],spZ[~falut_rows]\n",
    "\n",
    "    A = np.zeros((len(spX),4))\n",
    "    A[:,0] = spX*2\n",
    "    A[:,1] = spY*2\n",
    "    A[:,2] = spZ*2\n",
    "    A[:,3] = 1\n",
    "\n",
    "    #   Assemble the f matrix\n",
    "    f = np.zeros((len(spX),1))\n",
    "    f[:,0] = (spX*spX) + (spY*spY) + (spZ*spZ)\n",
    "    C, residules, rank, singval = np.linalg.lstsq(A,f)\n",
    "    C = np.abs(C)\n",
    "    #   solve for the radius\n",
    "    t = (C[0]*C[0])+(C[1]*C[1])+(C[2]*C[2])+C[3]\n",
    "    radius = np.sqrt(t)\n",
    "    # channels are switched\n",
    "    return radius, np.sqrt(C[1]), np.sqrt(C[0]), np.sqrt(C[2])\n",
    "\n",
    "rgb_img = rgb_images[-1]\n",
    "plt.imshow(rgb_img)\n",
    "plt.show()\n",
    "r = []\n",
    "w = []\n",
    "h = []\n",
    "z = []\n",
    "for i in range(len(pc_images)):\n",
    "    centers = pc_images[i][:,:,:3].reshape(-1,3)\n",
    "    filtered_center = centers.copy()\n",
    "    filtered_center[np.abs(centers[:,2]) > np.abs(np.nanmedian(centers[:,2]) + 2 * np.nanstd(centers[:,2]))] = np.nan\n",
    "    filtered_center[np.abs(centers[:,1]) > np.abs(np.nanmedian(centers[:,1]) + 2 * np.nanstd(centers[:,1]))] = np.nan\n",
    "    filtered_center[np.abs(centers[:,0]) > np.abs(np.nanmedian(centers[:,0]) + 2* np.nanstd(centers[:,0]))] = np.nan\n",
    "    r_t, w_t, h_t, z_t = ellipsoid_fit(filtered_center)\n",
    "    r.append(r_t)\n",
    "    w.append(w_t)\n",
    "    h.append(h_t)\n",
    "    z.append(z_t)\n",
    "np.mean(r), np.mean(w),np.mean(h),np.mean(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(r), np.std(w),np.std(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = filtered_center[:,1][~falut_rows],filtered_center[:,0][~falut_rows],filtered_center[:,2][~falut_rows]\n",
    "A = np.array([x**2, y**2, z**2]).T\n",
    "\n",
    "# vector of ones\n",
    "O = np.ones(len(x))\n",
    "\n",
    "# least squares solver\n",
    "B, resids, rank, s = np.linalg.lstsq(A, O)\n",
    "\n",
    "# solving for a, b, c\n",
    "a_ls = np.sqrt(1.0/B[0])\n",
    "b_ls = np.sqrt(1.0/B[1])\n",
    "c_ls = np.sqrt(1.0/B[2])\n",
    "a_ls, b_ls, c_ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FsCounter",
   "language": "python",
   "name": "fscounter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
